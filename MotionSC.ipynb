{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch._C import LongStorageBase\n",
    "\n",
    "sys.path.append(\"./Models\")\n",
    "from Models.utils import *\n",
    "from Data.dataset import CarlaDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pdb\n",
    "from PIL import Image\n",
    "import psutil\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from Models.MotionSC import MotionSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_287156/1565449510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mdecayRate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.96\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Put parameters here\n",
    "seed = 42\n",
    "x_dim = 128\n",
    "y_dim = 128\n",
    "z_dim = 8\n",
    "\n",
    "model_name = \"MotionSC\"\n",
    "\n",
    "num_classes = 23\n",
    "\n",
    "B = 8\n",
    "T = 16\n",
    "\n",
    "in_dim = num_classes + 3 + 3 # Input feature size per point\n",
    "enc_dim = 64 # Size of point pillars\n",
    "out_dim = 23 # Number of semantic classes\n",
    "\n",
    "train_dir = \"./Data/Scenes/Cartesian/Train\"\n",
    "val_dir = \"./Data/Scenes/Cartesian/Val\"\n",
    "cylindrical = False\n",
    "\n",
    "lr = 0.001\n",
    "epoch_num = 500\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "weights = torch.ones(num_classes)\n",
    "weights[0] = 0.1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "\n",
    "decayRate = 0.96\n",
    "\n",
    "writer = SummaryWriter(\"./Models/Runs/\" + model_name)\n",
    "save_dir = \"./Models/Weights/\" + model_name\n",
    "\n",
    "MODEL_PATH = None\n",
    "\n",
    "num_workers = 0\n",
    "\n",
    "VISUALIZE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_cartesian = np.asarray([88.01, 0.89, 0.18, 0.01, 0.02, 0.06, 0.14, 4.84, 2.38, 0.63, \n",
    "                    0.29, 0.33, 0.01, 0.01, 0.17, 0.01, 0.01, 0.19, 0.01, \n",
    "                    0.08, 0.07, 0.01, 1.68]) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carla_ds = CarlaDataset(directory=train_dir, device=device, num_frames=T, cylindrical=cylindrical)\n",
    "dataloader = DataLoader(carla_ds, batch_size=B, shuffle=True, collate_fn=carla_ds.collate_fn, num_workers=num_workers)\n",
    "\n",
    "val_ds = CarlaDataset(directory=val_dir, device=device, num_frames=T, cylindrical=cylindrical)\n",
    "dataloader_val = DataLoader(val_ds, batch_size=B, shuffle=True, collate_fn=val_ds.collate_fn, num_workers=num_workers)\n",
    "\n",
    "test_ds = CarlaDataset(directory=val_dir, device=device, num_frames=T, cylindrical=cylindrical)\n",
    "dataloader_test = DataLoader(test_ds, batch_size=1, shuffle=False, collate_fn=test_ds.collate_fn, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor_ranges = carla_ds._eval_param['min_bound'] + carla_ds._eval_param['max_bound']\n",
    "voxel_sizes = [abs(coor_ranges[3] - coor_ranges[0]) / x_dim, \n",
    "              abs(coor_ranges[4] - coor_ranges[1]) / y_dim,\n",
    "              abs(coor_ranges[5] - coor_ranges[2]) / z_dim] # since BEV\n",
    "\n",
    "model = MotionSC(voxel_sizes, coor_ranges, [x_dim, y_dim, z_dim], T=T, device=device)\n",
    "\n",
    "if MODEL_PATH:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "if VISUALIZE:\n",
    "    visualize_set(model, dataloader_test, carla_ds, cylindrical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "train_count = 0\n",
    "for epoch in range(epoch_num):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for input_data, output, counts in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_data = torch.tensor(input_data).to(device)\n",
    "        output = torch.tensor(output).to(device)\n",
    "        counts = torch.tensor(counts).to(device)\n",
    "        preds = model(input_data)\n",
    "         \n",
    "        counts = counts.view(-1)\n",
    "        output = output.view(-1).long()\n",
    "        preds = preds.contiguous().view(-1, preds.shape[4])\n",
    "\n",
    "        # Criterion requires input (NxC), output (N) dimension\n",
    "        mask = counts > 0\n",
    "        output_masked = output[mask]\n",
    "        preds_masked = preds[mask]\n",
    "        loss = criterion(preds_masked, output_masked)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accuracy\n",
    "        with torch.no_grad():\n",
    "            probs = nn.functional.softmax(preds_masked, dim=1)\n",
    "            preds_masked = np.argmax(probs.detach().cpu().numpy(), axis=1)\n",
    "            outputs_np = output_masked.detach().cpu().numpy()\n",
    "            accuracy = np.sum(preds_masked == outputs_np) / outputs_np.shape[0]\n",
    "            \n",
    "        # Record\n",
    "        writer.add_scalar(model_name + '/Loss/Train', loss.item(), train_count)\n",
    "        writer.add_scalar(model_name + '/Accuracy/Train', accuracy, train_count)\n",
    "            \n",
    "        train_count += input_data.shape[0]\n",
    "        \n",
    "    # Save model, decreaser learning rate\n",
    "    my_lr_scheduler.step()\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, \"Epoch\" + str(epoch) + \".pt\"))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        counter = 0\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for input_data, output, counts in dataloader_val:\n",
    "            optimizer.zero_grad()\n",
    "            input_data = torch.tensor(input_data).to(device)\n",
    "            output = torch.tensor(output).to(device)\n",
    "            counts = torch.tensor(counts).to(device)\n",
    "            preds = model(input_data)\n",
    "\n",
    "            counts = counts.view(-1)\n",
    "            output = output.view(-1).long()\n",
    "            preds = preds.contiguous().view(-1, preds.shape[4])\n",
    "\n",
    "            # Criterion requires input (NxC), output (N) dimension\n",
    "            mask = counts > 0\n",
    "            output_masked = output[mask]\n",
    "            preds_masked = preds[mask]\n",
    "            loss = criterion(preds_masked, output_masked)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            counter += input_data.shape[0]\n",
    "\n",
    "            # Accuracy\n",
    "            probs = nn.functional.softmax(preds_masked, dim=1)\n",
    "            preds_masked = np.argmax(probs.detach().cpu().numpy(), axis=1)\n",
    "            outputs_np = output_masked.detach().cpu().numpy()\n",
    "            num_correct += np.sum(preds_masked == outputs_np)\n",
    "            num_total += outputs_np.shape[0]\n",
    "        \n",
    "        print(f'Eppoch Num: {epoch} ------ average val loss: {running_loss/counter}')\n",
    "        print(f'Eppoch Num: {epoch} ------ average val accuracy: {num_correct/num_total}')\n",
    "        writer.add_scalar(model_name + '/Loss/Val', running_loss/counter, epoch)\n",
    "        writer.add_scalar(model_name + '/Accuracy/Val', num_correct/num_total, epoch)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
