{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = 16650\n",
    "t_end = 17000\n",
    "dt = 0.1\n",
    "seq_dir = \"02/\"\n",
    "save_dir = \"02_processed/\"\n",
    "\n",
    "voxel_resolution = 0.2\n",
    "grid_lengths = np.array([40.0, 40.0, 4.0])\n",
    "NUM_CLASSES = 25\n",
    "\n",
    "grid_dim = 2 * grid_lengths / voxel_resolution\n",
    "grid_dim = [int(grid_dim[0]), int(grid_dim[1]), int(grid_dim[2]), NUM_CLASSES] # 0 is free\n",
    "print(grid_dim)\n",
    "\n",
    "x = np.arange(-grid_lengths[0], grid_lengths[0], voxel_resolution) + voxel_resolution/2\n",
    "y = np.arange(-grid_lengths[1], grid_lengths[1], voxel_resolution) + voxel_resolution/2\n",
    "z = np.arange(-grid_lengths[2], grid_lengths[2], voxel_resolution) + voxel_resolution/2\n",
    "xv, yv, zv = np.meshgrid(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "sensors = glob.glob(seq_dir + \"velodyne*\")\n",
    "sensors = sorted([int(sensor.split(\"velodyne\")[1]) for sensor in sensors])\n",
    "ego_sensor = sensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "t_from = open(seq_dir + \"times0.txt\", \"r\")\n",
    "for t_stamp in t_from.readlines():\n",
    "    t_frame = t_stamp.split(\", \")[0]\n",
    "    if int(t_frame) < t_start:\n",
    "        continue\n",
    "    if int(t_frame) >= t_end:\n",
    "        continue\n",
    "    t_frame = (float(t_frame) - t_start) * dt\n",
    "    times.append(t_frame)\n",
    "t_from.close()\n",
    "\n",
    "times = np.array(times)\n",
    "print(times)\n",
    "np.savetxt(save_dir + 'times.txt', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_str(t_frame, t_start, t_end):\n",
    "    if int(t_frame) < t_start:\n",
    "        return None\n",
    "    if int(t_frame) >= t_end:\n",
    "        return None\n",
    "    t_frame = int(t_frame) - t_start\n",
    "    return str(t_frame).zfill(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original view\n",
    "poses = {}\n",
    "sorted_poses_all = {}\n",
    "inv_first = None \n",
    "for sensor in sensors:\n",
    "    poses[sensor] = {}\n",
    "    # Get poses\n",
    "    for pose_file in os.listdir(seq_dir + \"pose\" + str(sensor)):\n",
    "        t_frame = pose_file.split(\".\")[0]\n",
    "        frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "        if frame_str:\n",
    "            pose = np.load(seq_dir + \"pose\" + str(sensor) + \"/\" + pose_file)\n",
    "            poses[sensor][frame_str] = pose\n",
    "\n",
    "    # Sort poses\n",
    "    sorted_poses = [poses[sensor][fr] for fr in sorted(poses[sensor].keys())]\n",
    "    # Make first pose origin\n",
    "    if sensor == 0:\n",
    "        inv_first = np.linalg.inv(sorted_poses[0])\n",
    "    for i in range(len(sorted_poses)):\n",
    "        sorted_poses[i] = np.matmul(inv_first, sorted_poses[i])\n",
    "        sorted_poses[i] = sorted_poses[i].reshape(-1)[:12]\n",
    "\n",
    "    sorted_poses = np.array(sorted_poses)\n",
    "    if sensor == 0:\n",
    "        np.savetxt(save_dir + '/poses.txt', sorted_poses)\n",
    "    sorted_poses_all[sensor] = sorted_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for ego sensor\n",
    "def save_labels(view_num, query):\n",
    "    to_folder = save_dir + \"labels\"\n",
    "    if query:\n",
    "        to_folder += \"_query\"\n",
    "    to_folder += \"/\"\n",
    "    \n",
    "    if not os.path.exists(to_folder):\n",
    "        os.mkdir(to_folder)\n",
    "    \n",
    "    for label_file in os.listdir(seq_dir + \"labels\" + str(view_num)):\n",
    "        t_frame = label_file.split(\".\")[0]\n",
    "        frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "        if frame_str:\n",
    "            label = np.load(seq_dir + \"labels\" + str(view_num) + \"/\" + label_file)\n",
    "            label.astype('uint32').tofile(to_folder + frame_str + \".label\")\n",
    "            values, counts = np.unique(label, return_counts=True)\n",
    "            print(values, counts)\n",
    "        \n",
    "save_labels(0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "def save_points(view_num, query):\n",
    "    to_folder_points = save_dir + \"velodyne\"\n",
    "    to_folder_flow = save_dir + \"predictions\"\n",
    "    if query:\n",
    "        to_folder_points += \"_query\"\n",
    "        to_folder_flow += \"_query\"\n",
    "    to_folder_points += \"/\"\n",
    "    to_folder_flow += \"/\"\n",
    "    \n",
    "    if not os.path.exists(to_folder_points):\n",
    "        os.mkdir(to_folder_points)\n",
    "    if not os.path.exists(to_folder_flow):\n",
    "        os.mkdir(to_folder_flow)\n",
    "    \n",
    "    for point_file in os.listdir(seq_dir + \"velodyne\" + str(view_num)):\n",
    "        t_frame = point_file.split(\".\")[0]\n",
    "        frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "        if frame_str:\n",
    "            points = np.load(seq_dir + \"velodyne\" + str(view_num) + \"/\" + point_file) # Point cloud\n",
    "            instances = np.load(seq_dir + \"instances\" + str(view_num) + \"/\" + point_file) # Instances per point\n",
    "            velocities = np.load(seq_dir + \"velocities\" + str(view_num) + \"/\" + point_file) # Per-instance velocity\n",
    "            flow = np.zeros(points.shape, dtype=np.float32) # Actual movement of things\n",
    "            for row in velocities:\n",
    "                ind = int(row[0])\n",
    "                velocity = row[1:]\n",
    "                flow[instances == ind] = velocity\n",
    " \n",
    "            points = np.c_[points, np.zeros(points.shape[0])] # Dummy intensity\n",
    "            points.astype('float32').tofile(to_folder_points + frame_str + \".bin\")\n",
    "            flow.astype('float32').tofile(to_folder_flow + frame_str + \".bin\")\n",
    "        \n",
    "save_points(0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to create voxel grid\n",
    "def get_info(sensor, frame_str, seq_dir):\n",
    "    points = np.load(seq_dir + \"velodyne\" + str(sensor) + \"/\" + frame_str + \".npy\") # Point cloud\n",
    "    instances = np.load(seq_dir + \"instances\" + str(sensor) + \"/\" + frame_str + \".npy\") # Instances per point\n",
    "    velocities = np.load(seq_dir + \"velocities\" + str(sensor) + \"/\" + frame_str + \".npy\") # Per-instance velocity\n",
    "    flow = np.zeros(points.shape, dtype=np.float32) # Actual movement of things\n",
    "    for row in velocities:\n",
    "        ind = int(row[0])\n",
    "        velocity = row[1:]\n",
    "        flow[instances == ind] = velocity\n",
    "    label = np.load(seq_dir + \"labels\" + str(sensor) + \"/\" + frame_str + \".npy\")\n",
    "    return [points, instances, flow, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial transforms (other lidar to ego sensor)\n",
    "inv_transforms = {} \n",
    "for pose_file in os.listdir(seq_dir + \"pose0\"):\n",
    "    t_frame = pose_file.split(\".\")[0]\n",
    "    frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "    if frame_str:\n",
    "        ego_pose = np.load(seq_dir + \"pose0/\" + pose_file)\n",
    "        for sensor in sensors:\n",
    "            sensor_pose = np.load(seq_dir + \"pose\" + str(sensor) + \"/\" + pose_file)\n",
    "            inv_sensor = np.linalg.inv(sensor_pose)\n",
    "            inv_transforms[sensor] = np.matmul(ego_pose, inv_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_point(point, label, grid):\n",
    "    voxel = np.floor((point + grid_lengths) / voxel_resolution)\n",
    "    coords = [int(voxel[0]), int(voxel[1]), int(voxel[2]), int(label)]\n",
    "    if np.all(np.array(coords) < np.array(grid_dim)):\n",
    "        grid[coords[0], coords[1], coords[2], coords[3]] += 1\n",
    "    return grid\n",
    "\n",
    "# Vectorized\n",
    "def add_points(points, labels, grid):\n",
    "    # All voxels\n",
    "    voxels = np.floor((points + grid_lengths) / voxel_resolution).astype(int)\n",
    "    voxels = np.hstack((voxels, np.reshape(labels, (-1, 1))))\n",
    "    # Voxels within grid (check max and min)\n",
    "    valid_voxels = np.all(voxels < np.reshape(np.array(grid_dim), (1, -1)), axis=1) # Max\n",
    "    valid_voxels = voxels[valid_voxels]\n",
    "    valid_inds = np.all(valid_voxels >= 0, axis=1) # Min\n",
    "    valid_voxels = valid_voxels[valid_inds]\n",
    "    # Convert to list\n",
    "    valid_coords = [list(valid_voxels[:, 0]), list(valid_voxels[:, 1]), list(valid_voxels[:, 2]), list(valid_voxels[:, 3])]\n",
    "    \n",
    "    grid[valid_coords] += 1\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add points along ray to grid\n",
    "def ray_trace(point, label, grid, sample_spacing):\n",
    "    vec_norm = np.linalg.norm(point)\n",
    "    vec_angle = point / vec_norm\n",
    "    dists = np.arange(vec_norm, 0, -sample_spacing)\n",
    "    new_points = np.reshape(dists, (-1, 1)) * np.reshape(vec_angle, (1, 3))\n",
    "    labels = [0] * new_points.shape[0]\n",
    "    # End Point is label, free points all 0\n",
    "    labels[0] = label\n",
    "    grid = add_points(new_points, labels, grid)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether any measurements were found\n",
    "if not os.path.exists(save_dir + \"evaluation\"):\n",
    "    os.mkdir(save_dir + \"evaluation\")\n",
    "    \n",
    "\n",
    "# Create voxel grid\n",
    "for pose_file in os.listdir(seq_dir + \"pose0\"):\n",
    "    t_frame = pose_file.split(\".\")[0]\n",
    "    frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "    voxel_grid = np.zeros((grid_dim))\n",
    "    if frame_str:\n",
    "        for sensor in sensors:\n",
    "            [points, instances, flow, label] = get_info(sensor, t_frame, seq_dir) # Get info for sensor at frame\n",
    "            transformed_points = np.matmul(points, inv_transforms[sensor][:3, :3]) # Convert points to ego frame\n",
    "            transformed_points = transformed_points + inv_transforms[sensor][3, :3]\n",
    "            for i in range(transformed_points.shape[0]):\n",
    "                voxel_grid = ray_trace(transformed_points[i, :], label[i], voxel_grid, voxel_resolution)\n",
    "        # Save\n",
    "        valid_cells = np.sum(voxel_grid, axis=3) > 0\n",
    "        labels = np.argmax(voxel_grid, axis=3)\n",
    "        values, counts = np.unique(labels[valid_cells], return_counts=True)\n",
    "        print(frame_str, values, counts)\n",
    "        valid_x = xv[valid_cells]\n",
    "        valid_y = yv[valid_cells]\n",
    "        valid_z = zv[valid_cells]\n",
    "        valid_points = np.stack((valid_x, valid_y, valid_z)).T\n",
    "        valid_labels = labels[valid_cells]\n",
    "        valid_points.astype('float32').tofile(save_dir + \"/evaluation/\" + frame_str + \".bin\")\n",
    "        valid_labels.astype('uint32').tofile(save_dir + \"/evaluation/\" + frame_str + \".label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLORS = np.array([\n",
    "    (255, 255, 255), # None (free) 0\n",
    "    (70, 70, 70),    # Building 1\n",
    "    (100, 40, 40),   # Fences 2\n",
    "    (55, 90, 80),    # Other 3\n",
    "    (220, 20, 60),   # Pedestrian 4\n",
    "    (153, 153, 153), # Pole 5\n",
    "    (157, 234, 50),  # RoadLines 6\n",
    "    (128, 64, 128),  # Road 7\n",
    "    (244, 35, 232),  # Sidewalk 8\n",
    "    (107, 142, 35),  # Vegetation 9\n",
    "    (0, 0, 142),     # Vehicle 10\n",
    "    (102, 102, 156), # Wall 11\n",
    "    (220, 220, 0),   # TrafficSign 12\n",
    "    (70, 130, 180),  # Sky 13\n",
    "    (81, 0, 81),     # Ground 14\n",
    "    (150, 100, 100), # Bridge 15\n",
    "    (230, 150, 140), # RailTrack 16\n",
    "    (180, 165, 180), # GuardRail 17\n",
    "    (250, 170, 30),  # TrafficLight 18\n",
    "    (110, 190, 160), # Static 19\n",
    "    (170, 120, 50),  # Dynamic 20\n",
    "    (45, 60, 150),   # Water 21\n",
    "    (145, 170, 100), # Terrain 22\n",
    "]) / 255.0 # normalize each channel [0-1] since is what Open3D uses"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
