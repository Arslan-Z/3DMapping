{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd207c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = 510\n",
    "t_end = 580\n",
    "dt = 0.1\n",
    "seq_dir = \"/home/tigeriv/Data/Carla/02/\"\n",
    "save_dir = \"03_processed/\"\n",
    "\n",
    "voxel_resolution = 0.2 #0.2\n",
    "grid_lengths = np.array([40.0, 40.0, 4.0])\n",
    "NUM_CLASSES = 25\n",
    "\n",
    "grid_dim = 2 * grid_lengths / voxel_resolution\n",
    "grid_dim = [int(grid_dim[0]), int(grid_dim[1]), int(grid_dim[2]), NUM_CLASSES] # 0 is free\n",
    "print(grid_dim)\n",
    "\n",
    "x = np.arange(-grid_lengths[0], grid_lengths[0], voxel_resolution) + voxel_resolution/2\n",
    "y = np.arange(-grid_lengths[1], grid_lengths[1], voxel_resolution) + voxel_resolution/2\n",
    "z = np.arange(-grid_lengths[2], grid_lengths[2], voxel_resolution) + voxel_resolution/2\n",
    "xv, yv, zv = np.meshgrid(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cylindrical\n",
    "voxel_resolution_theta = voxel_resolution * (2*np.pi) / 40\n",
    "print(voxel_resolution_theta)\n",
    "r = np.arange(-grid_lengths[0], grid_lengths[0], voxel_resolution) + voxel_resolution/2\n",
    "theta = np.arange(-2.0*np.pi, 2.0*np.pi, voxel_resolution_theta) + voxel_resolution_theta/2\n",
    "z = np.arange(-grid_lengths[2], grid_lengths[2], voxel_resolution) + voxel_resolution/2\n",
    "rv, thetav, zv = np.meshgrid(r, theta, z)\n",
    "grid_dim_cylinder = [r.shape[0],theta.shape[0],z.shape[0],NUM_CLASSES]\n",
    "print(grid_dim_cylinder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2polar(input_xyz):\n",
    "        \"\"\"\n",
    "        Converts cartesian to polar coordinates\n",
    "\n",
    "        :param input_xyz_polar:  nx3 np array where rows are points and cols are x,y,z\n",
    "\n",
    "        :return: nx3 np array where rows are points and cols are r,theta,z\n",
    "        \"\"\"\n",
    "        rho = np.sqrt(input_xyz[:, 0] ** 2 + input_xyz[:, 1] ** 2)\n",
    "        phi = np.arctan2(input_xyz[:, 1], input_xyz[:, 0])\n",
    "        return np.stack((rho, phi, input_xyz[:, 2]), axis=1)\n",
    "\n",
    "\n",
    "def polar2cart(input_xyz_polar):\n",
    "    \"\"\"\n",
    "    Converts polar to cartesian coordinates\n",
    "\n",
    "    :param input_xyz_polar: nx3 np array where rows are points and cols are r,theta,z\n",
    "\n",
    "    :return: nx3 np array where rows are points and cols are x,y,z\n",
    "    \"\"\"\n",
    "    x = input_xyz_polar[:, 0] * np.cos(input_xyz_polar[:, 1])\n",
    "    y = input_xyz_polar[:, 0] * np.sin(input_xyz_polar[:, 1])\n",
    "\n",
    "    return np.stack((x, y, input_xyz_polar[:, 2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "sensors = glob.glob(seq_dir + \"velodyne*\")\n",
    "sensors = sorted([int(sensor.split(\"velodyne\")[1]) for sensor in sensors])\n",
    "ego_sensor = sensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267599f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "t_from = open(seq_dir + \"times0.txt\", \"r\")\n",
    "for t_stamp in t_from.readlines():\n",
    "    t_frame = t_stamp.split(\", \")[0]\n",
    "    if int(t_frame) < t_start:\n",
    "        continue\n",
    "    if int(t_frame) >= t_end:\n",
    "        continue\n",
    "    t_frame = (float(t_frame) - t_start) * dt\n",
    "    times.append(t_frame)\n",
    "t_from.close()\n",
    "\n",
    "times = np.array(times)\n",
    "print(times)\n",
    "np.savetxt(save_dir + 'times.txt', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_str(t_frame, t_start, t_end):\n",
    "    if int(t_frame) < t_start:\n",
    "        return None\n",
    "    if int(t_frame) >= t_end:\n",
    "        return None\n",
    "    t_frame = int(t_frame) - t_start\n",
    "    return str(t_frame).zfill(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original view\n",
    "poses = {}\n",
    "sorted_poses_all = {}\n",
    "inv_first = None \n",
    "for sensor in sensors:\n",
    "    poses[sensor] = {}\n",
    "    # Get poses\n",
    "    for pose_file in os.listdir(seq_dir + \"pose\" + str(sensor)):\n",
    "        t_frame = pose_file.split(\".\")[0]\n",
    "        frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "        if frame_str:\n",
    "            pose = np.load(seq_dir + \"pose\" + str(sensor) + \"/\" + pose_file)\n",
    "            poses[sensor][frame_str] = pose\n",
    "\n",
    "    # Sort poses\n",
    "    sorted_poses = [poses[sensor][fr] for fr in sorted(poses[sensor].keys())]\n",
    "    # Make first pose origin\n",
    "    if sensor == 0:\n",
    "        inv_first = np.linalg.inv(sorted_poses[0])\n",
    "    for i in range(len(sorted_poses)):\n",
    "        sorted_poses[i] = np.matmul(inv_first, sorted_poses[i])\n",
    "        sorted_poses[i] = sorted_poses[i].reshape(-1)[:12]\n",
    "\n",
    "    sorted_poses = np.array(sorted_poses)\n",
    "    if sensor == 0:\n",
    "        np.savetxt(save_dir + '/poses.txt', sorted_poses)\n",
    "    sorted_poses_all[sensor] = sorted_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for ego sensor\n",
    "def save_labels(view_num, query):\n",
    "    to_folder = save_dir + \"labels\"\n",
    "    if query:\n",
    "        to_folder += \"_query\"\n",
    "    to_folder += \"/\"\n",
    "    \n",
    "    if not os.path.exists(to_folder):\n",
    "        os.mkdir(to_folder)\n",
    "    \n",
    "    for label_file in os.listdir(seq_dir + \"labels\" + str(view_num)):\n",
    "        t_frame = label_file.split(\".\")[0]\n",
    "        frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "        if frame_str:\n",
    "            label = np.load(seq_dir + \"labels\" + str(view_num) + \"/\" + label_file)\n",
    "            label.astype('uint32').tofile(to_folder + frame_str + \".label\")\n",
    "            values, counts = np.unique(label, return_counts=True)\n",
    "            print(values, counts)\n",
    "        \n",
    "save_labels(0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c14d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "def save_points(view_num, query):\n",
    "    to_folder_points = save_dir + \"velodyne\"\n",
    "    to_folder_flow = save_dir + \"predictions\"\n",
    "    if query:\n",
    "        to_folder_points += \"_query\"\n",
    "        to_folder_flow += \"_query\"\n",
    "    to_folder_points += \"/\"\n",
    "    to_folder_flow += \"/\"\n",
    "    \n",
    "    if not os.path.exists(to_folder_points):\n",
    "        os.mkdir(to_folder_points)\n",
    "    if not os.path.exists(to_folder_flow):\n",
    "        os.mkdir(to_folder_flow)\n",
    "    \n",
    "    for point_file in os.listdir(seq_dir + \"velodyne\" + str(view_num)):\n",
    "        t_frame = point_file.split(\".\")[0]\n",
    "        frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "        if frame_str:\n",
    "            points = np.load(seq_dir + \"velodyne\" + str(view_num) + \"/\" + point_file) # Point cloud\n",
    "            instances = np.load(seq_dir + \"instances\" + str(view_num) + \"/\" + point_file) # Instances per point\n",
    "            velocities = np.load(seq_dir + \"velocities\" + str(view_num) + \"/\" + point_file) # Per-instance velocity\n",
    "            flow = np.zeros(points.shape, dtype=np.float32) # Actual movement of things\n",
    "            for row in velocities:\n",
    "                ind = int(row[0])\n",
    "                velocity = row[1:]\n",
    "                flow[instances == ind] = velocity\n",
    " \n",
    "            points = np.c_[points, np.zeros(points.shape[0])] # Dummy intensity\n",
    "            points.astype('float32').tofile(to_folder_points + frame_str + \".bin\")\n",
    "            flow.astype('float32').tofile(to_folder_flow + frame_str + \".bin\")\n",
    "        \n",
    "save_points(0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to create voxel grid\n",
    "def get_info(sensor, frame_str, seq_dir):\n",
    "    points = np.load(seq_dir + \"velodyne\" + str(sensor) + \"/\" + frame_str + \".npy\") # Point cloud\n",
    "    instances = np.load(seq_dir + \"instances\" + str(sensor) + \"/\" + frame_str + \".npy\") # Instances per point\n",
    "    velocities = np.load(seq_dir + \"velocities\" + str(sensor) + \"/\" + frame_str + \".npy\") # Per-instance velocity\n",
    "    flow = np.zeros(points.shape, dtype=np.float32) # Actual movement of things\n",
    "    for row in velocities:\n",
    "        ind = int(row[0])\n",
    "        velocity = row[1:]\n",
    "        flow[instances == ind] = velocity\n",
    "    label = np.load(seq_dir + \"labels\" + str(sensor) + \"/\" + frame_str + \".npy\")\n",
    "    return [points, instances, flow, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial transforms (other lidar to ego sensor)\n",
    "inv_transforms = {} \n",
    "for pose_file in os.listdir(seq_dir + \"pose0\"):\n",
    "    t_frame = pose_file.split(\".\")[0]\n",
    "    frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "    if frame_str:\n",
    "        ego_pose = np.load(seq_dir + \"pose0/\" + pose_file)\n",
    "        for sensor in sensors:\n",
    "            sensor_pose = np.load(seq_dir + \"pose\" + str(sensor) + \"/\" + pose_file)\n",
    "            inv_sensor = np.linalg.inv(sensor_pose)\n",
    "            inv_transforms[sensor] = np.matmul(ego_pose, inv_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_point(point, label, grid):\n",
    "    voxel = np.floor((point + grid_lengths) / voxel_resolution)\n",
    "    coords = [int(voxel[0]), int(voxel[1]), int(voxel[2]), int(label)]\n",
    "    if np.all(np.array(coords) < np.array(grid_dim)):\n",
    "        grid[coords[0], coords[1], coords[2], coords[3]] += 1\n",
    "    return grid\n",
    "\n",
    "# Vectorized\n",
    "def add_points(points, labels, grid):\n",
    "    # All voxels\n",
    "    voxels = np.zeros(points.shape).astype(int)\n",
    "    voxels[:,0] = np.floor((points[:,0] + grid_lengths[0]) / voxel_resolution).astype(int)\n",
    "    voxels[:,1] = np.floor((points[:,1] + 2*np.pi) / voxel_resolution_theta).astype(int)\n",
    "    voxels[:,2] = np.floor((points[:,2] + grid_lengths[2]) / voxel_resolution).astype(int)\n",
    "    voxels = np.hstack((voxels, np.reshape(labels, (-1, 1))))\n",
    "    # Voxels within grid (check max and min)\n",
    "    valid_voxels = np.all(voxels < np.reshape(np.array(grid_dim), (1, -1)), axis=1) # Max\n",
    "\n",
    "    valid_voxels = voxels[valid_voxels]\n",
    "    valid_inds = np.all(valid_voxels >= 0, axis=1) # Min\n",
    "    valid_voxels = valid_voxels[valid_inds]\n",
    "\n",
    "    # Convert to list\n",
    "    valid_coords = [list(valid_voxels[:, 0]), list(valid_voxels[:, 1]), list(valid_voxels[:, 2]), list(valid_voxels[:, 3])]\n",
    "    \n",
    "    grid[valid_coords] += 1\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add points along ray to grid\n",
    "def ray_trace(point, label, sample_spacing):\n",
    "    vec_norm = np.linalg.norm(point)\n",
    "    vec_angle = point / vec_norm\n",
    "    dists = np.arange(vec_norm, 0, -sample_spacing)\n",
    "    new_points = np.reshape(dists, (-1, 1)) * np.reshape(vec_angle, (1, 3))\n",
    "    labels = [0] * new_points.shape[0]\n",
    "    # End Point is label, free points all 0\n",
    "    labels[0] = label\n",
    "    return new_points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether any measurements were found\n",
    "if not os.path.exists(save_dir + \"evaluation\"):\n",
    "    os.mkdir(save_dir + \"evaluation\")\n",
    "    \n",
    "\n",
    "# Create voxel grid\n",
    "for pose_file in os.listdir(seq_dir + \"pose0\"):\n",
    "    t_frame = pose_file.split(\".\")[0]\n",
    "    frame_str = get_frame_str(t_frame, t_start, t_end)\n",
    "    voxel_grid = np.zeros((grid_dim))\n",
    "   \n",
    "    if frame_str:\n",
    "        for sensor in sensors:\n",
    "            [points, instances, flow, label] = get_info(sensor, t_frame, seq_dir) # Get info for sensor at frame\n",
    "            \n",
    "            for i in range(points.shape[0]):\n",
    "                temp_points, labels = ray_trace(points[i, :], label[i], voxel_resolution)\n",
    "                transformed_points = np.matmul(temp_points, inv_transforms[sensor][:3, :3]) # Convert points to ego frame\n",
    "                transformed_points = transformed_points + inv_transforms[sensor][3, :3]\n",
    "\n",
    "                polar_points = cart2polar(transformed_points)\n",
    "\n",
    "                voxel_grid = add_points(polar_points, labels, voxel_grid)\n",
    "\n",
    "        # Save\n",
    "        valid_cells = np.sum(voxel_grid, axis=3) > 0\n",
    "        labels = np.argmax(voxel_grid, axis=3)\n",
    "        values, counts = np.unique(labels[valid_cells], return_counts=True)\n",
    "        print(frame_str, values, counts)\n",
    "        valid_r = rv[valid_cells]\n",
    "        valid_theta = thetav[valid_cells]\n",
    "        valid_z = zv[valid_cells]\n",
    "        valid_points = np.stack((valid_r, valid_theta, valid_z)).T\n",
    "        valid_labels = labels[valid_cells]\n",
    "        valid_labels_arr = voxel_grid[valid_cells]\n",
    "        valid_points.astype('float32').tofile(save_dir + \"/evaluation/\" + frame_str + \".bin\")\n",
    "        valid_labels.astype('uint32').tofile(save_dir + \"/evaluation/\" + frame_str + \".label\")\n",
    "        valid_labels_arr.astype('uint32').tofile(save_dir + \"/evaluation/\" + \"labelarray\" +frame_str +\".label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLORS = np.array([\n",
    "    (255, 255, 255), # None (free) 0\n",
    "    (70, 70, 70),    # Building 1\n",
    "    (100, 40, 40),   # Fences 2\n",
    "    (55, 90, 80),    # Other 3\n",
    "    (220, 20, 60),   # Pedestrian 4\n",
    "    (153, 153, 153), # Pole 5\n",
    "    (157, 234, 50),  # RoadLines 6\n",
    "    (128, 64, 128),  # Road 7\n",
    "    (244, 35, 232),  # Sidewalk 8\n",
    "    (107, 142, 35),  # Vegetation 9\n",
    "    (0, 0, 142),     # Vehicle 10\n",
    "    (102, 102, 156), # Wall 11\n",
    "    (220, 220, 0),   # TrafficSign 12\n",
    "    (70, 130, 180),  # Sky 13\n",
    "    (81, 0, 81),     # Ground 14\n",
    "    (150, 100, 100), # Bridge 15\n",
    "    (230, 150, 140), # RailTrack 16\n",
    "    (180, 165, 180), # GuardRail 17\n",
    "    (250, 170, 30),  # TrafficLight 18\n",
    "    (110, 190, 160), # Static 19\n",
    "    (170, 120, 50),  # Dynamic 20\n",
    "    (45, 60, 150),   # Water 21\n",
    "    (145, 170, 100), # Terrain 22\n",
    "]) / 255.0 # normalize each channel [0-1] since is what Open3D uses"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
